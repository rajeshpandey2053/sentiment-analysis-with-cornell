{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.3\n",
      "3.2.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews(path,positive=True):\n",
    "    label = 1 if positive else 0\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "        review_text = f.readlines()\n",
    "    reviews = []\n",
    "    for text in review_text:\n",
    "        #returns a tuple of the review text and a label whether it is a positve or negative review\n",
    "        reviews.append((text,label))\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews():\n",
    "    positive_reviews = get_reviews(\"rt-polarity.pos\", positive=True)\n",
    "    negative_reviews = get_reviews(\"rt-polarity.neg\" , positive=False)\n",
    "    \n",
    "    return positive_reviews, negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews, negative_reviews = extract_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n',\n",
       "  1),\n",
       " ('the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth . \\n',\n",
       "  1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = 5000\n",
    "TOTAL_DATA = len(positive_reviews)\n",
    "\n",
    "train_reviews = positive_reviews[:TRAIN_DATA] + negative_reviews[:TRAIN_DATA]\n",
    "\n",
    "test_positive_reviews = positive_reviews[TRAIN_DATA:TOTAL_DATA]\n",
    "test_negative_reviews = negative_reviews[TRAIN_DATA: TOTAL_DATA]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(train_reviews):\n",
    "    words_set= set()\n",
    "    \n",
    "    for review in train_reviews:\n",
    "        words_set.update(review[0].split())\n",
    "    \n",
    "    return list(words_set)\n",
    "\n",
    "vocabulary = get_vocabulary(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20703"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guiÃ³n', 'mismo', 'cumbersome', 'waste', 'lynchings']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(review_text):\n",
    "    #split the review into words and create a set of the words\n",
    "    review_words = set(review_text.split())\n",
    "    \n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word] = (word in review_words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = nltk.classify.apply_features(extract_features, train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_calculator(review_text):\n",
    "    features = extract_features(review_text)\n",
    "    return trained_classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"what an amazing movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"this is not a bad movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator):\n",
    "    positive_results = [sentiment_calculator(review[0]) for review in test_positive_reviews]\n",
    "    negative_results = [sentiment_calculator(review[0]) for review in test_negative_reviews]\n",
    "    \n",
    "    true_positives = sum(x > 0 for x in positive_results)\n",
    "    true_negatives = sum(x == 0 for x in negative_results)\n",
    "    \n",
    "    percent_true_positive = float(true_positives) / len(positive_results)\n",
    "    percent_true_negative = float(true_negatives) / len(negative_results)\n",
    "\n",
    "    total_accurate = true_positives + true_negatives\n",
    "    total = len(positive_results) + len(negative_results)\n",
    "\n",
    "    print(\"Accuracy on positive reviews = \" +\"%.2f\" % (percent_true_positive * 100) + \"%\")\n",
    "    print(\"Accurance on negative reviews = \" +\"%.2f\" % (percent_true_negative * 100) + \"%\")\n",
    "    print(\"Overall accuracy = \" + \"%.2f\" % (total_accurate * 100/ total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 78.25%\n",
      "Accurance on negative reviews = 80.66%\n",
      "Overall accuracy = 79.46%\n"
     ]
    }
   ],
   "source": [
    "classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
